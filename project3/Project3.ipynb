{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d288dcd8-b489-488a-9bab-fc2c4ab602e1",
   "metadata": {},
   "source": [
    "# Project 3 - Hurricane Harvey Image Classification Using Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3d2325-b6a3-4dd9-bd2a-45df72220d64",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "800ea3d4-db07-4aab-b7a7-63622632564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "try:\n",
    "    shutil.rmtree(\"./data/split/train\")\n",
    "    shutil.rmtree(\"./data/split/test\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3765e787-8962-43c4-9657-4c0dbc7fa220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "Path(\"./data/split/train/damage\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"./data/split/train/no_damage\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "Path(\"./data/split/test/damage\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"./data/split/test/no_damage\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29c401ac-8f40-4d47-9ede-d53c8110fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_damage_file_paths = os.listdir('./data/damage')\n",
    "all_no_damage_file_paths = os.listdir('./data/no_damage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a26c7f75-0c5e-4abe-ac07-7c056ba5f570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train damage image count:  11336\n",
      "test damage image count:  2834\n",
      "len of overlap:  0\n",
      "train no_damage image count:  5721\n",
      "test no_damage image count:  1431\n",
      "len of overlap:  0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "train_damage_paths = random.sample(all_damage_file_paths, int(len(all_damage_file_paths)*0.8))\n",
    "print(\"train damage image count: \", len(train_damage_paths))\n",
    "test_damage_paths = [ p for p in all_damage_file_paths if p not in train_damage_paths]\n",
    "print(\"test damage image count: \", len(test_damage_paths))\n",
    "# ensure no overlap:\n",
    "overlap = [p for p in train_damage_paths if p in test_damage_paths]\n",
    "print(\"len of overlap: \", len(overlap))\n",
    "\n",
    "train_no_damage_paths = random.sample(all_no_damage_file_paths, int(len(all_no_damage_file_paths)*0.8))\n",
    "print(\"train no_damage image count: \", len(train_no_damage_paths))\n",
    "test_no_damage_paths = [ p for p in all_no_damage_file_paths if p not in train_no_damage_paths]\n",
    "print(\"test no_damage image count: \", len(test_no_damage_paths))\n",
    "# ensure no overlap:\n",
    "overlap = [p for p in train_no_damage_paths if p in test_no_damage_paths]\n",
    "print(\"len of overlap: \", len(overlap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e604728-cc81-4f08-846a-f4f8790b2d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in train/damage:  11336\n",
      "Files in train/no_damage:  5721\n",
      "Files in test/damage:  2834\n",
      "Files in test/no_damage:  1431\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "for p in train_damage_paths:\n",
    "    shutil.copyfile(os.path.join('./data/damage', p), os.path.join('./data/split/train/damage', p) )\n",
    "\n",
    "for p in test_damage_paths:\n",
    "    shutil.copyfile(os.path.join('./data/damage', p), os.path.join('./data/split/test/damage', p) )\n",
    "\n",
    "for p in train_no_damage_paths:\n",
    "    shutil.copyfile(os.path.join('./data/no_damage', p), os.path.join('./data/split/train/no_damage', p) )\n",
    "\n",
    "for p in test_no_damage_paths:\n",
    "    shutil.copyfile(os.path.join('./data/no_damage', p), os.path.join('./data/split/test/no_damage', p) )\n",
    "\n",
    "# check counts:\n",
    "print(\"Files in train/damage: \", len(os.listdir(\"./data/split/train/damage\")))\n",
    "print(\"Files in train/no_damage: \", len(os.listdir(\"./data/split/train/no_damage\")))\n",
    "\n",
    "print(\"Files in test/damage: \", len(os.listdir(\"./data/split/test/damage\")))\n",
    "print(\"Files in test/no_damage: \", len(os.listdir(\"./data/split/test/no_damage\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a08adbb4-6aeb-414a-babc-43e738b1ccb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 04:01:32.560057: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-11 04:01:32.603503: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-11 04:01:32.603565: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-11 04:01:32.605299: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-11 04:01:32.613775: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-11 04:01:32.615666: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-11 04:01:33.779275: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17057 files belonging to 2 classes.\n",
      "Using 13646 files for training.\n",
      "Using 3411 files for validation.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "train_data_dir = 'data/split/train/'\n",
    "\n",
    "batch_size = 32\n",
    "# target image size\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "\n",
    "# note that subset=\"training\", \"validation\", \"both\", and dictates which dataset is returned\n",
    "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "train_data_dir,\n",
    "validation_split=0.2,\n",
    "subset=\"both\",\n",
    "seed=123,\n",
    "image_size=(img_height, img_width),\n",
    "batch_size=batch_size\n",
    ")\n",
    "rescale = Rescaling(scale=1.0/255)\n",
    "train_rescale_ds = train_ds.map(lambda image,label:(rescale(image),label))\n",
    "val_rescale_ds = val_ds.map(lambda image,label:(rescale(image),label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee778b37-9ec2-4faa-8ca0-87854332a1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4265 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_dir = 'data/split/test/'\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "# this is what was used in the paper --\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "\n",
    "# note that subset=\"training\", \"validation\", \"both\", and dictates what is returned\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "test_data_dir,\n",
    "seed=123,\n",
    "image_size=(img_height, img_width),\n",
    ")\n",
    "\n",
    "# approach 1: manually rescale data --\n",
    "rescale = Rescaling(scale=1.0/255)\n",
    "test_rescale_ds = test_ds.map(lambda image,label:(rescale(image),label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845cace9-9ea7-47e5-9b22-bddbefa2ec81",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d10566d-d079-45c3-b5fc-992ddf6d5487",
   "metadata": {},
   "source": [
    "### Artificial Neural Network (ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d740013a-220f-4032-92bd-9ed61af3f02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 49152)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               25166336  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25357441 (96.73 MB)\n",
      "Trainable params: 25357441 (96.73 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "model_ann = Sequential() # initialize model\n",
    "\n",
    "# First layer\n",
    "model_ann.add(Flatten(input_shape=(128,128, 3)))\n",
    "\n",
    "model_ann.add(Dense(512, activation='relu'))\n",
    "model_ann.add(Dense(256, activation='relu'))\n",
    "model_ann.add(Dense(128, activation='relu'))\n",
    "model_ann.add(Dense(128, activation='relu'))\n",
    "model_ann.add(Dense(64, activation='relu'))\n",
    "model_ann.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Use sigmoid for last layer because problem is binary (damage or no damage)\n",
    "model_ann.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model_ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Generating summary of model\n",
    "model_ann.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2559efa-a79e-4114-b7b6-81fbe02013b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "427/427 [==============================] - 76s 176ms/step - loss: 0.7101 - accuracy: 0.6456 - val_loss: 0.6752 - val_accuracy: 0.6681\n",
      "Epoch 2/20\n",
      "427/427 [==============================] - 76s 178ms/step - loss: 0.6162 - accuracy: 0.6816 - val_loss: 0.5954 - val_accuracy: 0.6681\n",
      "Epoch 3/20\n",
      "427/427 [==============================] - 78s 182ms/step - loss: 0.6011 - accuracy: 0.6828 - val_loss: 0.5909 - val_accuracy: 0.6837\n",
      "Epoch 4/20\n",
      "427/427 [==============================] - 77s 180ms/step - loss: 0.5974 - accuracy: 0.6975 - val_loss: 0.6141 - val_accuracy: 0.6687\n",
      "Epoch 5/20\n",
      "427/427 [==============================] - 73s 171ms/step - loss: 0.5856 - accuracy: 0.7091 - val_loss: 0.5969 - val_accuracy: 0.6866\n",
      "Epoch 6/20\n",
      "427/427 [==============================] - 75s 174ms/step - loss: 0.5790 - accuracy: 0.7154 - val_loss: 0.5932 - val_accuracy: 0.6848\n",
      "Epoch 7/20\n",
      "427/427 [==============================] - 74s 173ms/step - loss: 0.5860 - accuracy: 0.7072 - val_loss: 0.5636 - val_accuracy: 0.7215\n",
      "Epoch 8/20\n",
      "427/427 [==============================] - 78s 182ms/step - loss: 0.5623 - accuracy: 0.7332 - val_loss: 0.5896 - val_accuracy: 0.6951\n",
      "Epoch 9/20\n",
      "427/427 [==============================] - 74s 174ms/step - loss: 0.5885 - accuracy: 0.7061 - val_loss: 0.5872 - val_accuracy: 0.7039\n",
      "Epoch 10/20\n",
      "427/427 [==============================] - 74s 172ms/step - loss: 0.5880 - accuracy: 0.7002 - val_loss: 0.5788 - val_accuracy: 0.7033\n",
      "Epoch 11/20\n",
      "427/427 [==============================] - 73s 172ms/step - loss: 0.5548 - accuracy: 0.7386 - val_loss: 0.5960 - val_accuracy: 0.6884\n",
      "Epoch 12/20\n",
      "427/427 [==============================] - 78s 182ms/step - loss: 0.5601 - accuracy: 0.7324 - val_loss: 0.5559 - val_accuracy: 0.7218\n",
      "Epoch 13/20\n",
      "427/427 [==============================] - 76s 179ms/step - loss: 0.5546 - accuracy: 0.7389 - val_loss: 0.5755 - val_accuracy: 0.7027\n",
      "Epoch 14/20\n",
      "427/427 [==============================] - 78s 182ms/step - loss: 0.5665 - accuracy: 0.7202 - val_loss: 0.5604 - val_accuracy: 0.6681\n",
      "Epoch 15/20\n",
      "427/427 [==============================] - 76s 178ms/step - loss: 0.5828 - accuracy: 0.6989 - val_loss: 0.5604 - val_accuracy: 0.7353\n",
      "Epoch 16/20\n",
      "427/427 [==============================] - 78s 182ms/step - loss: 0.6263 - accuracy: 0.6720 - val_loss: 0.6289 - val_accuracy: 0.6681\n",
      "Epoch 17/20\n",
      "427/427 [==============================] - 77s 179ms/step - loss: 0.5802 - accuracy: 0.6954 - val_loss: 0.6496 - val_accuracy: 0.4527\n",
      "Epoch 18/20\n",
      "427/427 [==============================] - 75s 175ms/step - loss: 0.5743 - accuracy: 0.6947 - val_loss: 0.5544 - val_accuracy: 0.7294\n",
      "Epoch 19/20\n",
      "427/427 [==============================] - 75s 176ms/step - loss: 0.5879 - accuracy: 0.7031 - val_loss: 0.5545 - val_accuracy: 0.7291\n",
      "Epoch 20/20\n",
      "427/427 [==============================] - 76s 179ms/step - loss: 0.5578 - accuracy: 0.7226 - val_loss: 0.5707 - val_accuracy: 0.7039\n"
     ]
    }
   ],
   "source": [
    "history = model_ann.fit(\n",
    "            train_rescale_ds,\n",
    "            batch_size=32,\n",
    "            epochs=20,\n",
    "            validation_data=val_rescale_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8078e89e-175e-4acc-8881-d8c4530644fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5654383897781372\n",
      "Test Accuracy: 0.7064478397369385\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model_ann.evaluate(test_rescale_ds, verbose=0)\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8610c294-d7d5-45fd-9c2c-f38b1305afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ann.save('./models/ann.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb19f7b-5ef1-4401-8627-6bf4a81e2bd5",
   "metadata": {},
   "source": [
    "### LeNet-5 CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43aa4392-f7a7-482c-b116-5f81eabdf6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 126, 6)       168       \n",
      "                                                                 \n",
      " average_pooling2d (Average  (None, 63, 63, 6)         0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 16)        880       \n",
      "                                                                 \n",
      " average_pooling2d_1 (Avera  (None, 30, 30, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 14400)             0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 120)               1728120   \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1739417 (6.64 MB)\n",
      "Trainable params: 1739417 (6.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models, optimizers\n",
    "import pandas as pd\n",
    "\n",
    "model_lenet5 = models.Sequential()\n",
    "\n",
    "# Layer 1: Convolutional layer with 6 filters of size 3x3, followed by average pooling\n",
    "model_lenet5.add(layers.Conv2D(6, kernel_size=(3, 3), activation='relu', input_shape=(128,128,3)))\n",
    "model_lenet5.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2: Convolutional layer with 16 filters of size 3x3, followed by average pooling\n",
    "model_lenet5.add(layers.Conv2D(16, kernel_size=(3, 3), activation='relu'))\n",
    "model_lenet5.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the feature maps to feed into fully connected layers\n",
    "model_lenet5.add(layers.Flatten())\n",
    "\n",
    "# Layer 3: Fully connected layer with 120 neurons\n",
    "model_lenet5.add(layers.Dense(120, activation='relu'))\n",
    "\n",
    "# Layer 4: Fully connected layer with 84 neurons\n",
    "model_lenet5.add(layers.Dense(84, activation='relu'))\n",
    "\n",
    "# Output layer: Fully connected layer with 1 neuron\n",
    "model_lenet5.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model_lenet5.compile(optimizer=optimizers.RMSprop(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Generating the summary of the model\n",
    "model_lenet5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98cc23dd-5c50-4e15-ab86-d3db2abe6790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "427/427 [==============================] - 26s 61ms/step - loss: 0.6331 - accuracy: 0.6688 - val_loss: 0.6053 - val_accuracy: 0.6992\n",
      "Epoch 2/20\n",
      "427/427 [==============================] - 25s 59ms/step - loss: 0.5942 - accuracy: 0.7050 - val_loss: 0.5734 - val_accuracy: 0.7051\n",
      "Epoch 3/20\n",
      "427/427 [==============================] - 25s 59ms/step - loss: 0.5532 - accuracy: 0.7388 - val_loss: 0.5145 - val_accuracy: 0.7575\n",
      "Epoch 4/20\n",
      "427/427 [==============================] - 25s 59ms/step - loss: 0.4974 - accuracy: 0.7799 - val_loss: 0.4464 - val_accuracy: 0.8182\n",
      "Epoch 5/20\n",
      "427/427 [==============================] - 25s 58ms/step - loss: 0.4506 - accuracy: 0.8098 - val_loss: 0.5357 - val_accuracy: 0.7455\n",
      "Epoch 6/20\n",
      "427/427 [==============================] - 25s 58ms/step - loss: 0.4227 - accuracy: 0.8265 - val_loss: 0.4380 - val_accuracy: 0.7930\n",
      "Epoch 7/20\n",
      "427/427 [==============================] - 25s 59ms/step - loss: 0.4061 - accuracy: 0.8416 - val_loss: 0.3726 - val_accuracy: 0.8528\n",
      "Epoch 8/20\n",
      "427/427 [==============================] - 25s 58ms/step - loss: 0.3904 - accuracy: 0.8422 - val_loss: 0.4004 - val_accuracy: 0.8517\n",
      "Epoch 9/20\n",
      "427/427 [==============================] - 25s 59ms/step - loss: 0.3724 - accuracy: 0.8524 - val_loss: 0.3389 - val_accuracy: 0.8769\n",
      "Epoch 10/20\n",
      "427/427 [==============================] - 25s 59ms/step - loss: 0.3465 - accuracy: 0.8663 - val_loss: 0.3946 - val_accuracy: 0.8229\n",
      "Epoch 11/20\n",
      "427/427 [==============================] - 25s 59ms/step - loss: 0.3296 - accuracy: 0.8727 - val_loss: 0.3192 - val_accuracy: 0.8713\n",
      "Epoch 12/20\n",
      "427/427 [==============================] - 25s 59ms/step - loss: 0.3133 - accuracy: 0.8792 - val_loss: 0.2822 - val_accuracy: 0.9059\n",
      "Epoch 13/20\n",
      "427/427 [==============================] - 25s 59ms/step - loss: 0.2962 - accuracy: 0.8880 - val_loss: 0.2755 - val_accuracy: 0.9012\n",
      "Epoch 14/20\n",
      "427/427 [==============================] - 25s 58ms/step - loss: 0.2854 - accuracy: 0.8900 - val_loss: 0.3384 - val_accuracy: 0.8663\n",
      "Epoch 15/20\n",
      "427/427 [==============================] - 25s 58ms/step - loss: 0.2720 - accuracy: 0.8954 - val_loss: 0.2554 - val_accuracy: 0.9068\n",
      "Epoch 16/20\n",
      "427/427 [==============================] - 25s 59ms/step - loss: 0.2595 - accuracy: 0.8975 - val_loss: 0.4996 - val_accuracy: 0.7473\n",
      "Epoch 17/20\n",
      "427/427 [==============================] - 25s 59ms/step - loss: 0.2553 - accuracy: 0.9016 - val_loss: 0.2513 - val_accuracy: 0.9088\n",
      "Epoch 18/20\n",
      "427/427 [==============================] - 25s 58ms/step - loss: 0.2448 - accuracy: 0.9042 - val_loss: 0.3317 - val_accuracy: 0.8654\n",
      "Epoch 19/20\n",
      "427/427 [==============================] - 25s 59ms/step - loss: 0.2384 - accuracy: 0.9090 - val_loss: 0.2469 - val_accuracy: 0.9085\n",
      "Epoch 20/20\n",
      "427/427 [==============================] - 25s 57ms/step - loss: 0.2310 - accuracy: 0.9127 - val_loss: 0.2932 - val_accuracy: 0.8836\n"
     ]
    }
   ],
   "source": [
    "history = model_lenet5.fit(\n",
    "            train_rescale_ds,\n",
    "            batch_size=32,\n",
    "            epochs=20,\n",
    "            validation_data=val_rescale_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06ef3f64-9f9b-4fc7-9ec2-755b72ebd905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.291168749332428\n",
      "Test Accuracy: 0.8874560594558716\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model_lenet5.evaluate(test_rescale_ds, verbose=0)\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acd62388-c40a-4d79-9b3e-e01bd17cddf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lenet5.save('./models/lenet5.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cce5a93-7591-463f-8586-c3203ad59c7f",
   "metadata": {},
   "source": [
    "### Alternate LeNet-5 CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b42d2fbc-52a3-4e8f-914c-f9e2013040df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 63, 63, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 30, 30, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 14, 14, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 12, 12, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 6, 6, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               2359808   \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2601153 (9.92 MB)\n",
      "Trainable params: 2601153 (9.92 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import MaxPooling2D, Dropout, Conv2D\n",
    "from keras import optimizers\n",
    "\n",
    "model_altlenet5 = Sequential()\n",
    "\n",
    "model_altlenet5.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128,128,3)))\n",
    "model_altlenet5.add(MaxPooling2D((2, 2)))\n",
    "model_altlenet5.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_altlenet5.add(MaxPooling2D((2, 2)))\n",
    "model_altlenet5.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_altlenet5.add(MaxPooling2D((2, 2)))\n",
    "model_altlenet5.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_altlenet5.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the feature maps to feed into fully connected layers\n",
    "model_altlenet5.add(Flatten())\n",
    "\n",
    "model_altlenet5.add(Dropout(0.5))\n",
    "\n",
    "model_altlenet5.add(Dense(512, activation='relu'))\n",
    "model_altlenet5.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model_altlenet5.compile(optimizer=optimizers.RMSprop(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Generating the summary of the model\n",
    "model_altlenet5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4233e2e9-5c5b-49e3-8ae9-75617d03fae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "427/427 [==============================] - 95s 221ms/step - loss: 0.5617 - accuracy: 0.7229 - val_loss: 0.4533 - val_accuracy: 0.8250\n",
      "Epoch 2/20\n",
      "427/427 [==============================] - 96s 224ms/step - loss: 0.4155 - accuracy: 0.8237 - val_loss: 0.4145 - val_accuracy: 0.8194\n",
      "Epoch 3/20\n",
      "427/427 [==============================] - 92s 216ms/step - loss: 0.3174 - accuracy: 0.8717 - val_loss: 0.2994 - val_accuracy: 0.8804\n",
      "Epoch 4/20\n",
      "427/427 [==============================] - 94s 219ms/step - loss: 0.2438 - accuracy: 0.9030 - val_loss: 0.1920 - val_accuracy: 0.9249\n",
      "Epoch 5/20\n",
      "427/427 [==============================] - 91s 214ms/step - loss: 0.1988 - accuracy: 0.9221 - val_loss: 0.2004 - val_accuracy: 0.9235\n",
      "Epoch 6/20\n",
      "427/427 [==============================] - 93s 217ms/step - loss: 0.1714 - accuracy: 0.9313 - val_loss: 0.1371 - val_accuracy: 0.9499\n",
      "Epoch 7/20\n",
      "427/427 [==============================] - 95s 222ms/step - loss: 0.1461 - accuracy: 0.9421 - val_loss: 0.1981 - val_accuracy: 0.9229\n",
      "Epoch 8/20\n",
      "427/427 [==============================] - 92s 216ms/step - loss: 0.1274 - accuracy: 0.9488 - val_loss: 0.1174 - val_accuracy: 0.9537\n",
      "Epoch 9/20\n",
      "427/427 [==============================] - 93s 219ms/step - loss: 0.1168 - accuracy: 0.9519 - val_loss: 0.1790 - val_accuracy: 0.9288\n",
      "Epoch 10/20\n",
      "427/427 [==============================] - 94s 220ms/step - loss: 0.1069 - accuracy: 0.9578 - val_loss: 0.1192 - val_accuracy: 0.9522\n",
      "Epoch 11/20\n",
      "427/427 [==============================] - 93s 219ms/step - loss: 0.1010 - accuracy: 0.9601 - val_loss: 0.0869 - val_accuracy: 0.9666\n",
      "Epoch 12/20\n",
      "427/427 [==============================] - 91s 213ms/step - loss: 0.0951 - accuracy: 0.9623 - val_loss: 0.0857 - val_accuracy: 0.9648\n",
      "Epoch 13/20\n",
      "427/427 [==============================] - 94s 220ms/step - loss: 0.0878 - accuracy: 0.9658 - val_loss: 0.0743 - val_accuracy: 0.9719\n",
      "Epoch 14/20\n",
      "427/427 [==============================] - 93s 218ms/step - loss: 0.0847 - accuracy: 0.9666 - val_loss: 0.0838 - val_accuracy: 0.9672\n",
      "Epoch 15/20\n",
      "427/427 [==============================] - 95s 223ms/step - loss: 0.0808 - accuracy: 0.9689 - val_loss: 0.0725 - val_accuracy: 0.9695\n",
      "Epoch 16/20\n",
      "427/427 [==============================] - 95s 223ms/step - loss: 0.0770 - accuracy: 0.9702 - val_loss: 0.0728 - val_accuracy: 0.9701\n",
      "Epoch 17/20\n",
      "427/427 [==============================] - 94s 219ms/step - loss: 0.0712 - accuracy: 0.9713 - val_loss: 0.1641 - val_accuracy: 0.9390\n",
      "Epoch 18/20\n",
      "427/427 [==============================] - 95s 222ms/step - loss: 0.0687 - accuracy: 0.9737 - val_loss: 0.0730 - val_accuracy: 0.9695\n",
      "Epoch 19/20\n",
      "427/427 [==============================] - 92s 216ms/step - loss: 0.0668 - accuracy: 0.9743 - val_loss: 0.1769 - val_accuracy: 0.9267\n",
      "Epoch 20/20\n",
      "427/427 [==============================] - 96s 226ms/step - loss: 0.0641 - accuracy: 0.9749 - val_loss: 0.0754 - val_accuracy: 0.9721\n"
     ]
    }
   ],
   "source": [
    "history = model_altlenet5.fit(\n",
    "            train_rescale_ds,\n",
    "            batch_size=32,\n",
    "            epochs=20,\n",
    "            validation_data=val_rescale_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2fffdc2-9437-4f6d-bfc7-482e57a7c573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.08642759919166565\n",
      "Test Accuracy: 0.9645955562591553\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model_altlenet5.evaluate(test_rescale_ds, verbose=0)\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "561f7900-0c63-4eec-b3ec-b90bb456f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_altlenet5.save('./models/altlenet5.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
